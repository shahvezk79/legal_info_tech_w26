{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahvezk79/legal_info_tech_w26/blob/main/Module2_assignment_w26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Assignment"
      ],
      "metadata": {
        "id": "eFCArjxeHuR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "\n",
        "You should begin by viewing Lesson 2 on eClass (and note that the lesson includes a link to the notebook used in the videos).\n",
        "\n",
        "Next, everyone should attempt to complete the beginner and intermediate sections of this assignment. If you are interested you can continue to advanced. Whether you choose to go beyond the beginner and intermediate sections will not affect your participation grade, but some of the skills you learn (or relearn) may be helpful for your final project for the course.\n",
        "\n",
        "In addition, everyone should complete the final reflection section.\n",
        "\n",
        "Combined, the lesson and assignment should not take you more than three hours -- so if you get to that point, just move on to the reflective section (and add a text/markdown cell to the notebook indicating where you stopped and saying that you hit the 3 hour limit).\n",
        "\n",
        "When you have finished, upload a copy of the .ipynb file to eClass assignment page.\n",
        "\n",
        "NOTE: If you are using Colab and you downloaded this file by clicking a link, make sure to save a copy of this file on your Google Drive by selecting File, Save."
      ],
      "metadata": {
        "id": "MxZsmxPBH-Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 1:\n",
        "\n",
        "Create a text file called courses.txt with the names of each of the courses that you are taking this year (each course on one line)."
      ],
      "metadata": {
        "id": "XZwaYTu8IGOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "courses = [\n",
        "    \"Evidence\",\n",
        "    \"Real Estate Transactions\",\n",
        "    \"Wills and Estates\",\n",
        "    \"Legal Engineering\",\n",
        "    \"Criminal Procedure\",\n",
        "    \"Construction Law\",\n",
        "    \"Legal Info Tech\",\n",
        "    \"Neurotechnology and Human Rights\"\n",
        "]\n",
        "\n",
        "with open(\"courses.txt\", \"w\") as file:\n",
        "    for course in courses:\n",
        "        file.write(course + \"\\n\")\n",
        "\n",
        "print(\"File 'courses.txt' has been created successfully!\")"
      ],
      "metadata": {
        "id": "Eq60bwrDWQGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6245f3-bd99-4107-c854-ea1140775c24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'courses.txt' has been created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I utilized generative AI (Gemini 3.0 Thinking) to generate the code.\n",
        "Prompt:\n",
        "For this entire chat, assume the code should be in Python, and that you're dealing with someone incredibly new to coding and python. I'm completing an assignment and I need your help with generating the code.\n",
        "\n",
        "\n",
        "\n",
        "First question:\n",
        "\n",
        "Create a text file called courses.txt with the names of each of the courses that you are taking this year (each course on one line).\n",
        "\n",
        "\n",
        "\n",
        "The courses I'm taking this year are:\n",
        "\n",
        "Evidence\n",
        "\n",
        "Real Estate Transactions\n",
        "\n",
        "Wills and Estates\n",
        "\n",
        "Legal Engineering\n",
        "\n",
        "Criminal Procedure\n",
        "\n",
        "Construction Law\n",
        "\n",
        "Legal Info Tech\n",
        "\n",
        "Neurotechnology and Human Rights"
      ],
      "metadata": {
        "id": "_-CEDXq1M4L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 2:\n",
        "\n",
        "Find a course summary (yours or one that you find online) for an Osgoode Hall Law School course in MS Word docx format.\n",
        "\n",
        "Extract the text of the document into a variable called: course_summary\n",
        "\n",
        "Print the first 20 characters of each of the first 20 paragraphs of the course_summary variable"
      ],
      "metadata": {
        "id": "Ca5ARYegWQ_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "\n",
        "import docx\n",
        "\n",
        "file_name = 'Criminal Procedure (Tanguary-Renaud) - 2025 Summary.docx'\n",
        "doc = docx.Document(file_name)\n",
        "\n",
        "course_summary = \"\"\n",
        "for para in doc.paragraphs:\n",
        "    if para.text.strip():\n",
        "        course_summary += para.text + \"\\n\"\n",
        "\n",
        "paragraphs_list = course_summary.split('\\n')\n",
        "\n",
        "for i in range(min(20, len(paragraphs_list))):\n",
        "    current_paragraph = paragraphs_list[i]\n",
        "    print(f\"Para {i+1}: {current_paragraph[:20]}\")"
      ],
      "metadata": {
        "id": "0wyzhXh7ovTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84713a59-fdde-4e3c-f243-abb4287b5aab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Para 1: Criminal Code\n",
            "Para 2: Note, under s. 492, \n",
            "Para 3: This reminds judges \n",
            "Para 4: Controlled Drugs & S\n",
            "Para 5: Charter\n",
            "Para 6: INTRODUCTION, BACKGR\n",
            "Para 7: We look to many USSC\n",
            "Para 8: Note that US cases a\n",
            "Para 9: The stakes for defin\n",
            "Para 10: In US law, once ther\n",
            "Para 11: In Canadian law, s. \n",
            "Para 12: Allows Canadian cour\n",
            "Para 13: E.g., in the context\n",
            "Para 14: SEARCH & SEIZURE \n",
            "Para 15: Basic Framework \n",
            "Para 16: A search under s. 8 \n",
            "Para 17: Thus, if someone doe\n",
            "Para 18: Evidence adduced mus\n",
            "Para 19: One way to challenge\n",
            "Para 20: Solov piece:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I used generative AI (Gemini 3.0 thinking) to generate the code. Prompt:\n",
        "\n",
        "Question 2 (I attached the docx file but I'm doing this assignment in Google Colab, so advise on how to do this)\n",
        "\n",
        "Find a course summary (yours or one that you find online) for an Osgoode Hall Law School course in MS Word docx format.\n",
        "Extract the text of the document into a variable called: course_summary\n",
        "Print the first 20 characters of each of the first 20 paragraphs of the course_summary variable\n",
        "\n",
        "Initially the code it gave me returned an error, however after investigating the traceback I determined it was because the file path was incorrect, and the next iteration from Gemini fixed it."
      ],
      "metadata": {
        "id": "ac41sp47NHG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 3:\n",
        "\n",
        "Create a pandas dataframe using data about refugee claims decided in 2019 available at: https://refugeelab.ca/wp-content/uploads/2024/06/2019_RPD_Data.xlsx\n",
        "\n",
        "Using the dataframe, list the 10 counsel who worked on the largest number of refugee claims in 2019."
      ],
      "metadata": {
        "id": "Jvp-e9yOQeiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/2019_RPD_Data.xlsx'\n",
        "\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "top_10_counsel = df['Counsel Fullname'].value_counts().head(10).reset_index()\n",
        "\n",
        "top_10_counsel.columns = ['Counsel Name', 'Number of Claims']\n",
        "\n",
        "print(\"The 10 counsel who worked on the largest number of refugee claims in 2019:\")\n",
        "print(top_10_counsel)"
      ],
      "metadata": {
        "id": "BvNrJhqXRcfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2008c380-a976-404e-d946-4e78a84c0d6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 10 counsel who worked on the largest number of refugee claims in 2019:\n",
            "              Counsel Name  Number of Claims\n",
            "0  CINTOSUN, BRIAN IBRAHIM               285\n",
            "1          Singer, Melissa               269\n",
            "2   Siryuyumusi, Pacifique               240\n",
            "3       Desjardins, Odette               177\n",
            "4            GRICE, JOHN W               170\n",
            "5        VALOIS, Stéphanie               170\n",
            "6        MARKAKI, STYLIANI               164\n",
            "7            IVANYI, PETER               162\n",
            "8         LOEBACH, MICHAEL               160\n",
            "9            HAMILTON, IAN               158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I used Gemini 3.0 Thinking to generate the code. Prompt:\n",
        "\n",
        "Question 3 (path to the relevant dataframe is /content/2019_RPD_Data.xlsx and I've also attached it here)\n",
        "\n",
        "Beginner Question 3:\n",
        "Create a pandas dataframe using data about refugee claims decided in 2019\n",
        "\n",
        "Using the dataframe, list the 10 counsel who worked on the largest number of refugee claims in 2019."
      ],
      "metadata": {
        "id": "kvN4EXOuNjQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 1:\n",
        "\n",
        "Using the same dataframe about refugee claims in 2019 from Beginner Question 3, filter the dataframe so that it only includes positive and negative decisions (excluding claims that were otherwise resolved, such as claims that were abandoned).\n",
        "\n",
        "Using the filtered dataframe, caculate and print the grant rates for the ten highest volume counsel, listed from highest grant rate to lowest grant rate."
      ],
      "metadata": {
        "id": "szBeP6bzXXGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/2019_RPD_Data.xlsx')\n",
        "\n",
        "filtered_df = df[df['Explanation'].isin(['Positive', 'Negative'])].copy()\n",
        "\n",
        "top_10_names = filtered_df['Counsel Fullname'].value_counts().head(10).index\n",
        "\n",
        "df_top_10 = filtered_df[filtered_df['Counsel Fullname'].isin(top_10_names)]\n",
        "\n",
        "summary = df_top_10.groupby(['Counsel Fullname', 'Explanation']).size().unstack(fill_value=0)\n",
        "\n",
        "summary['Total'] = summary['Positive'] + summary['Negative']\n",
        "summary['Grant Rate'] = (summary['Positive'] / summary['Total']) * 100\n",
        "\n",
        "summary_sorted = summary.sort_values(by='Grant Rate', ascending=False)\n",
        "\n",
        "print(\"Grant Rates for the 10 Highest Volume Counsel (Sorted High to Low):\")\n",
        "print(summary_sorted[['Positive', 'Negative', 'Total', 'Grant Rate']])"
      ],
      "metadata": {
        "id": "0JrZyf9wOb3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ca62d6-224d-4983-80df-08b59f6f06aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grant Rates for the 10 Highest Volume Counsel (Sorted High to Low):\n",
            "Explanation              Positive  Negative  Total  Grant Rate\n",
            "Counsel Fullname                                              \n",
            "TATHAM, MARY                  108         9    117   92.307692\n",
            "CINTOSUN, BRIAN IBRAHIM       168        18    186   90.322581\n",
            "HAMILTON, IAN                 129        21    150   86.000000\n",
            "KORMAN, MICHAEL                94        37    131   71.755725\n",
            "LOEBACH, MICHAEL               85        40    125   68.000000\n",
            "VALOIS, Stéphanie              83        41    124   66.935484\n",
            "GRICE, JOHN W                  76        44    120   63.333333\n",
            "Singer, Melissa                96        91    187   51.336898\n",
            "KABATERAINE, NKUNDA            57        65    122   46.721311\n",
            "MENGHILE, Claudette            47        69    116   40.517241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I used Gemini 3.0 to generate the code. Prompt:\n",
        "\n",
        "Intermediate Question 1:\n",
        "Using the same dataframe about refugee claims in 2019 from Beginner Question 3, filter the dataframe so that it only includes positive and negative decisions (excluding claims that were otherwise resolved, such as claims that were abandoned).\n",
        "Using the filtered dataframe, caculate and print the grant rates for the ten highest volume counsel, listed from highest grant rate to lowest grant rate."
      ],
      "metadata": {
        "id": "tz6UJ6UbNsOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 2:\n",
        "\n",
        "The lesson videos show you how to engage with the Refugee Law Lab's Bulk Decisions Dataset using [Hugging Face Datasets](https://huggingface.co/datasets/refugee-law-lab/canadian-legal-data).\n",
        "\n",
        "In 2025, responsibility for this dataset was transfered to [Access to Algorithmic Justice](https://a2aj.ca). The A2AJ dataset works largely the same way, although there are different fields.\n",
        "\n",
        "Review the documentation for the A2AJ datasets [here](https://huggingface.co/datasets/a2aj/canadian-case-law) and [here](https://github.com/a2aj-ca/canadian-legal-data).\n",
        "\n",
        "Download the Ontario Court of Appeal dataset, convert it to a pandas dataframe. Then print the citation and name of the case for the most recent decision in that dataframe.\n"
      ],
      "metadata": {
        "id": "pf2UXletSIQu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQKLzSJWhg6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 3:\n",
        "\n",
        "In addition to bulk downloads, the A2AJ also makes its data available via an Application Programming Interface. Review documentation about using that API [here](https://github.com/a2aj-ca/canadian-legal-data/blob/main/access-via-api.ipynb).\n",
        "\n",
        "Using the API, programmatically download the text of section 167 of the Immigration and Refugee Protection Act and print it."
      ],
      "metadata": {
        "id": "Hr4g6bKchkAH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpdRUKkBmqTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Question 1:\n",
        "\n",
        "Scrape the biographies of all judges on the Ontario Court of Appeal's [website](https://www.ontariocourts.ca/coa/judges-of-the-court/), and put them into a dataframe that includes the name of the judge, the text of the judge's biography, the URL where the biography is found, and the date/time when you scraped the biography\n"
      ],
      "metadata": {
        "id": "vuRR79MLmreY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5UOlpRGAPvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reflection\n",
        "\n",
        "If you could work with any legal data programmatically what data would you like to have access to?\n",
        "\n",
        "Does that data currently exist in a publicly accessible format that can be easily integrated into Python programs?\n",
        "\n",
        "If not, why not?"
      ],
      "metadata": {
        "id": "B1dB6sivAgx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I could work with any legal data programmatically, I would like to have access to settlement details and amounts. The reason I would like to work with this data would be to build a tool that allows potential litigants to understand the average settlement amounts for specific facts/causes of action (e.g., the average settlement amount for a icy walkway slip and fall that resulted in a sprained knee).\n",
        "\n",
        "This data does not currently exist in a publicly accessible format that can easily be integrated into Python programs. The reason for this is that settlement amounts are not generally made public, and are often subject to non-disclosure agreements. Regardless, if this tool could be created, it would resolve a lot of uncertainty for potential claimants/litigants, and allow them to make better-informed decisions."
      ],
      "metadata": {
        "id": "wZsK_nMhBTTL"
      }
    }
  ]
}